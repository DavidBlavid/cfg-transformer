{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### download a word2vec model\n",
    "wv = api.load('word2vec-google-news-300')\n",
    "\n",
    "# save the model\n",
    "wv.save('word2vec-google-news-300.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.save('word2vec-google-news-300.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    'data/sarcasm_headlines/Sarcasm_Headlines_Dataset.json',\n",
    "    'data/sarcasm_headlines/Sarcasm_Headlines_Dataset_v2.json'\n",
    "]\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in open(self.filename, 'r'):\n",
    "            data = json.loads(line)\n",
    "            headline = data['headline']\n",
    "            # Basic preprocessing\n",
    "            headline = re.sub(r'\\W+', ' ', headline).lower().split()\n",
    "            yield headline\n",
    "\n",
    "# Initialize the generator\n",
    "sentences = MySentences(paths[0])  # Path to your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 55328 sentences\n"
     ]
    }
   ],
   "source": [
    "### load the datasets\n",
    "# save the sentences in here\n",
    "sentences = []\n",
    "\n",
    "# the paths to the datasets\n",
    "paths = [\n",
    "    'data/sarcasm_headlines/Sarcasm_Headlines_Dataset.json',\n",
    "    'data/sarcasm_headlines/Sarcasm_Headlines_Dataset_v2.json'\n",
    "]\n",
    "\n",
    "for path in paths:\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            # load the json\n",
    "            json_line = json.loads(line)\n",
    "            headline = json_line['headline']\n",
    "            tokens = headline.split(' ')\n",
    "\n",
    "            # only use sarcastic headlines\n",
    "            # if not json_line['is_sarcastic']:\n",
    "            #     continue\n",
    "            \n",
    "            # append the headline to the sentences\n",
    "            sentences.append(tokens)\n",
    "\n",
    "print(f'Loaded {len(sentences)} sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "# get all keys of the model\n",
    "keys = list(model.wv.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between platinum and spraying: 0.9082143902778625\n",
      "Similarity between devour and conscious: 0.9656654000282288\n",
      "Similarity between commits and availability: 0.32744503021240234\n",
      "Similarity between creek and blankets: 0.9295600056648254\n",
      "Similarity between inappropriate and prequel: 0.8712742924690247\n",
      "Similarity between song and hairstyles: 0.9204217195510864\n",
      "Similarity between bandmates and val: 0.91707843542099\n",
      "Similarity between coats and shot: 0.9589670300483704\n",
      "Similarity between darkness and adequately: 0.8801407217979431\n",
      "Similarity between unveiled and arby: 0.8504656553268433\n"
     ]
    }
   ],
   "source": [
    "### similarity checker\n",
    "N_REPETITIONS = 10\n",
    "\n",
    "for i in range(N_REPETITIONS):\n",
    "    # get two random words\n",
    "    word1 = np.random.choice(keys)\n",
    "    word2 = np.random.choice(keys)\n",
    "\n",
    "    # print the similarity\n",
    "    print(f'Similarity between {word1} and {word2}: {model.wv.similarity(word1, word2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    'king', 'queen', 'man', 'woman', 'paris', 'berlin', 'car', 'bicycle', 'pizza', 'pasta',\n",
    "    'dog', 'cat', 'apple', 'orange', 'happy', 'sad', 'city', 'village', 'mountain', 'river',\n",
    "    'sun', 'moon', 'star', 'planet', 'ocean', 'lake', 'coffee', 'tea', 'book', 'newspaper',\n",
    "    'rain', 'snow', 'summer', 'winter', 'morning', 'night', 'music', 'silence', 'computer', 'smartphone',\n",
    "    'science', 'art', 'mathematics', 'literature', 'football', 'basketball', 'guitar', 'piano', 'eagle', 'sparrow',\n",
    "    'rose', 'tulip', 'tree', 'grass', 'gold', 'silver', 'milk', 'water', 'butterfly', 'bee',\n",
    "    'love', 'hate', 'peace', 'war', 'rich', 'poor', 'health', 'disease', 'strength', 'weakness',\n",
    "    'magic', 'science', 'fantasy', 'reality', 'dream', 'nightmare', 'hero', 'villain', 'comedy', 'tragedy',\n",
    "    'fire', 'ice', 'light', 'darkness', 'truth', 'lie', 'history', 'future', 'friend', 'enemy',\n",
    "    'north', 'south', 'east', 'west', 'earth', 'mars', 'jupiter', 'saturn', 'universe', 'galaxy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(word1, word2, word3, result):\n",
    "    for r in result:\n",
    "        print(f\"Result of {word1} - {word3} + {word2}: {r[0]} ({r[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of meow - cat + dog: woof_woof (0.5396372079849243)\n"
     ]
    }
   ],
   "source": [
    "base = 'meow'\n",
    "subtract = 'cat'\n",
    "add = 'dog'\n",
    "\n",
    "result = wv.most_similar(positive=[base, add], negative=[subtract], topn=1)\n",
    "print_result(base, add, subtract, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of science - car + west: east (0.51700758934021)\n",
      "Result of truth - tea + night: tonight (0.4257323443889618)\n",
      "Result of ocean - rain + dog: dogs (0.528801679611206)\n",
      "Result of eagle - paris + nightmare: bogey (0.42562130093574524)\n",
      "Result of water - tree + tulip: freshwater (0.4894673228263855)\n",
      "Result of friend - poor + villain: pal (0.5515633225440979)\n",
      "Result of king - disease + poor: kings (0.4762413501739502)\n",
      "Result of moon - tree + sun: waning_gibbous (0.5550332069396973)\n",
      "Result of winter - music + sad: winters (0.4633391499519348)\n",
      "Result of paris - darkness + man: woman (0.44301486015319824)\n",
      "Result of cat - mountain + hero: puppy (0.4813304543495178)\n",
      "Result of fantasy - smartphone + rain: downpour (0.4814264476299286)\n",
      "Result of health - happy + pizza: heath (0.5098319053649902)\n",
      "Result of weakness - silver + planet: Earth (0.4377327263355255)\n",
      "Result of friend - happy + bicycle: bike (0.5242830514907837)\n",
      "Result of love - milk + paris: luv (0.4688273072242737)\n",
      "Result of lake - sparrow + milk: water (0.5217375755310059)\n",
      "Result of love - tulip + paris: luv (0.49267521500587463)\n",
      "Result of west - silver + woman: north (0.5928038954734802)\n",
      "Result of tulip - dream + coffee: teas (0.5244069695472717)\n",
      "Result of city - pizza + rich: citys (0.43776586651802063)\n",
      "Result of weakness - science + cat: Doberman (0.48085060715675354)\n",
      "Result of reality - summer + star: Jaap_Amesz_Dutch (0.5698363780975342)\n",
      "Result of mars - war + villain: villian (0.4822279214859009)\n",
      "Result of art - football + history: postimpressionist (0.4755151569843292)\n",
      "Result of universe - poor + morning: afternoon (0.5000643134117126)\n",
      "Result of lake - pasta + butterfly: lakes (0.4854447543621063)\n",
      "Result of ocean - galaxy + sun: sea (0.5416504740715027)\n",
      "Result of literature - universe + snow: snowfall (0.506348192691803)\n",
      "Result of friend - woman + disease: diseases (0.5193766355514526)\n",
      "Result of rich - history + night: evening (0.49890992045402527)\n",
      "Result of paris - darkness + lie: bennett (0.4109174311161041)\n",
      "Result of lie - piano + cat: lies (0.48205024003982544)\n",
      "Result of mountain - queen + universe: mountains (0.5020186305046082)\n",
      "Result of sparrow - future + tulip: sparrows (0.5407187342643738)\n",
      "Result of pasta - tea + history: tricolored_battles (0.40323933959007263)\n",
      "Result of smartphone - fire + disease: smartphones (0.5893959999084473)\n",
      "Result of book - galaxy + fire: books (0.4230497181415558)\n",
      "Result of rose - light + berlin: climbed (0.5050423741340637)\n",
      "Result of rose - truth + love: climbed (0.5253018140792847)\n",
      "Result of poor - weakness + water: potable_water (0.5548060536384583)\n",
      "Result of silence - reality + morning: afternoon (0.5619937777519226)\n",
      "Result of lie - bee + love: lies (0.4826244115829468)\n",
      "Result of truth - queen + night: truths (0.4309479594230652)\n",
      "Result of smartphone - darkness + rose: smartphones (0.5349979400634766)\n",
      "Result of tulip - berlin + milk: strawberry (0.5397013425827026)\n",
      "Result of piano - strength + poor: violin (0.495459645986557)\n",
      "Result of saturn - science + ocean: sea (0.4869469404220581)\n",
      "Result of paris - sun + winter: october (0.35819345712661743)\n",
      "Result of snow - west + east: snowfall (0.8082207441329956)\n"
     ]
    }
   ],
   "source": [
    "N_REPETITIONS = 50\n",
    "\n",
    "for i in range(N_REPETITIONS):\n",
    "\n",
    "    word1 = word2 = word3 = None\n",
    "\n",
    "    # get three different words\n",
    "    while word1 == word2 or word1 == word3 or word2 == word3:\n",
    "        # get three random words\n",
    "        word1 = np.random.choice(words)\n",
    "        word2 = np.random.choice(words)\n",
    "        word3 = np.random.choice(words)\n",
    "    \n",
    "    result = wv.most_similar(positive=[word1, word2], negative=[word3], topn=1)\n",
    "    print(f\"Result of {word1} - {word3} + {word2}: {result[0][0]} ({result[0][1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of 'king' - 'man' + 'woman': queen (0.7118193507194519)\n"
     ]
    }
   ],
   "source": [
    "result = wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(f\"Result of 'king' - 'man' + 'woman': {result[0][0]} ({result[0][1]})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
